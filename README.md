# Data-Lakehouse-with-Dremio-Amazon-S3-and-Airbyte
The purpose of this project were to build a Data Lakehouse for distributed processing of extracts data from industrial equipment sensors. We started with the ELT process using Airbyte and after the data were moved to Amazon S3. For the distributed processing we used Dremio Data Lakehouse and SQL to analyse the dataset.

## Services provided:
- [x] Airbyte for automating data extract.
- [x] Amazon S3 to store the raw data.
- [x] Dremio Data Lakehouse to transform and process unstructured data.
      
## Developed Skills:
- [x] Google Drive
- [x]	AWS S3
- [x]	Airbyte
- [x]	Dremio
- [x]	SQL
